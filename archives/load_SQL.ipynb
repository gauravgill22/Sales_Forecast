{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar as calendar\n",
    "import psycopg2\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "from psycopg2.extensions import register_adapter, AsIs\n",
    "\n",
    "def addapt_numpy_float64(numpy_float64):\n",
    "    return AsIs(numpy_float64)\n",
    "\n",
    "def addapt_numpy_int64(numpy_int64):\n",
    "    return AsIs(numpy_int64)\n",
    "\n",
    "register_adapter(np.float64, addapt_numpy_float64)\n",
    "register_adapter(np.int64, addapt_numpy_int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Custom Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import yelp_api_key, darksky_api_key, postgres_user, postgres_pw\n",
    "from restaurant_info import restaurantLocation\n",
    "from weather import Weather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Latitude & Longitude from Yelp API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_business = 'The Counting Room' # Not the actual Restaurant \n",
    "location = 'Brooklyn, NY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weather Location: The Counting Room\n"
     ]
    }
   ],
   "source": [
    "# Make Yelp API Call to get Latitude & Longitude for Business\n",
    "rest_loc = restaurantLocation(search_business, location)\n",
    "lat, long = rest_loc.get_lat_long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Darksky API Call for Date Range as of specific time for given Latitude & Longitude\n",
    "w_start = '2017-01-01'\n",
    "w_end = '2019-06-30'\n",
    "\n",
    "weather_call = Weather(lat, long,'19:30:00')\n",
    "weather_df = weather_call.weather_df(w_start, w_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df.to_csv(f'csv/weather_{w_start}_to_{w_end}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import / Clean / Prep File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restaurant File\n",
    "sales_file = 'csv/new_through_06_09_separate_outside.csv'\n",
    "\n",
    "# Weather File\n",
    "weather_csv_file = f'csv/weather_{w_start}_to_{w_end}.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create & Populate SQL Database with Historical Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Sales Data for Postgres  Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sql_load(sales_file):\n",
    "    \n",
    "        # Read in Sales File\n",
    "        data = pd.read_csv(sales_file, index_col = 'date', parse_dates=True)\n",
    "        df = pd.DataFrame(data)\n",
    "\n",
    "        # Rename Column to 'sales'\n",
    "        df = df.rename(columns={'net_sales': 'sales'})\n",
    "\n",
    "        # Fill NaN\n",
    "        df.fillna(0, inplace=True)\n",
    "        \n",
    "        # Create ID Primary Key from Datetime\n",
    "        df['id'] = df.index.strftime('%Y%m%d')\n",
    "        \n",
    "        df = df[['id', 'sales', 'covers', 'outside']]\n",
    "        \n",
    "        return df\n",
    "    \n",
    "to_sql_sales_df = sql_load(sales_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Weather Data for Postgres Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sql_load_weather(weather_file):\n",
    "\n",
    "    # Read in Weather File\n",
    "    data = pd.read_csv(weather_file, index_col = 'date', parse_dates=True)\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Create ID Primary Key from Datetime\n",
    "    df['date_id'] = df.index.strftime('%Y%m%d')\n",
    "    \n",
    "    return df\n",
    "\n",
    "to_sql_weather_df = sql_load_weather(weather_csv_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to & Load Original CSV Files into SQL Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = sqlalchemy.create_engine(f\"postgresql+psycopg2://{postgres_user}:{postgres_pw}@localhost/rest_1_daily_sales\")\n",
    "con = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Open Connection\n",
    "conn = psycopg2.connect(f\"dbname=rest_1_daily_sales user={postgres_user} password={postgres_pw}\")\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create & Load Sales Data into SQL Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Sales Table\n",
    "cur.execute(\"CREATE TABLE daily_sales ( \\\n",
    "                DATE DATE, \\\n",
    "                id INT PRIMARY KEY, \\\n",
    "                sales NUMERIC (7, 2), \\\n",
    "                covers INT, \\\n",
    "                outside INT);\")\n",
    "\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Prediction Table\n",
    "cur.execute(\"CREATE TABLE sales_predictions ( \\\n",
    "                DATE DATE, \\\n",
    "                id INT PRIMARY KEY, \\\n",
    "                sales_predictions NUMERIC (7, 2), \\\n",
    "                predict_as_of DATE);\")\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append DF to Table\n",
    "to_sql_sales_df.to_sql('daily_sales', con=engine, if_exists='append')\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create & Load Weather Data into SQL Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Open Connection\n",
    "conn = psycopg2.connect(f\"dbname=rest_1_daily_sales user={postgres_user} password={postgres_pw}\")\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Table\n",
    "cur.execute(\"CREATE TABLE daily_weather ( \\\n",
    "                DATE DATE, \\\n",
    "                date_id INT PRIMARY KEY, \\\n",
    "                apparent_temperature NUMERIC (4, 2), \\\n",
    "                humidity NUMERIC (3, 2), \\\n",
    "                precip_intensity_max NUMERIC (5, 4), \\\n",
    "                precip_max_time TIME, \\\n",
    "                precip_prob NUMERIC (3, 2), \\\n",
    "                precip_type TEXT, \\\n",
    "                pressure NUMERIC (6,2), \\\n",
    "                summary TEXT, \\\n",
    "                temperature NUMERIC (4, 2), \\\n",
    "                day_of_week INT, \\\n",
    "                month INT);\")\n",
    "\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Append Existing CSV to Table\n",
    "to_sql_weather_df.to_sql('daily_weather', con=engine, if_exists='append')\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create & Load Sales Data into SQL Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Open Connection\n",
    "conn = psycopg2.connect(f\"dbname=rest_1_daily_sales user={postgres_user} password={postgres_pw}\")\n",
    "cur = conn.cursor()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
